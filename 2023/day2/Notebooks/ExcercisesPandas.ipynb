{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "guilty-steam",
   "metadata": {},
   "source": [
    "## Excercises pandas\n",
    "\n",
    "Let's practice data exploration and wrangling in Pandas. \n",
    "\n",
    "We will work with data collected through the Twitter API (RIP, more on API's and how quickly we're loosing them next week ;)). Few months ago (last days when the API was alive) we collected different tweets (for teaching purposes). We have also already run a sentiment analysis on these tweets and have saved it in a separate file.\n",
    "\n",
    "We have two datasets per account/topic:\n",
    "* One datasets with tweets (public tweets by account or with a hashtag)\n",
    "* One dataset with sentiment of those tweets (with three sentiment scores using veeery basic snetiment tool - more on how bad it is in two weeks ;))\n",
    "\n",
    "We want to see how sentiment changes over time, compare number of positive and negative tweets and analyze the relation between sentiment and engagement with the tweets. You can selest an account/topic that seems interesting to you.\n",
    "\n",
    "We want to prepare the dataset for analysis:\n",
    "\n",
    "**Morning**\n",
    "\n",
    "* Data exploration\n",
    "    * Check columns, data types, missing values, descriptives for numeric variables measuring engagement and sentiment, value_counts for relevant categorical variables\n",
    "* Handling missing values and data types\n",
    "    * Handle missing values in variables of interest: number of likes and retweets - what can nan's mean?\n",
    "    * Make sure created_at has the right format (to use it for aggregation later)\n",
    "* Creating necessary variables (sentiment)\n",
    "    * Overall measure of sentiment - create it from positive and negative\n",
    "    * Binary variable (positive or negative tweet) - Tip: Write a function that \"recodes\" the sentiment column\n",
    "    \n",
    "\n",
    "**Afternoon**\n",
    "\n",
    "* Merging the files (tweets with sentiment)\n",
    "    * Make sure the columns you merge match and check how to merge\n",
    "* Agrregating the files per month\n",
    "    * Tip: Create a column for month by transforming the date column. Remember that the date column needs the right format first!\n",
    "    `df['month'] = df['date_dt_column'].dt.strftime('%Y-%m')` \n",
    "* Visualisations:\n",
    "    * Visualise different columns of the tweet dataset (change of sentiment over time, sentiment, engagement, relation between sentiment and engagement)\n",
    "    * But *more fun*: use your own data to play with visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accredited-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jsonl = pd.read_json('filename', lines=True) #put your filename as filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell \n",
    "\n",
    "def get_public_metrics(row):\n",
    "    if 'public_metrics' in row.keys():\n",
    "        if type(row['public_metrics']) == dict:\n",
    "            for key, value in row['public_metrics'].items():\n",
    "                row['metric_' + str(key)] = value\n",
    "    return row\n",
    "\n",
    "def get_tweets(df):\n",
    "    if 'data' not in df.columns:\n",
    "        return None\n",
    "    results = pd.DataFrame()\n",
    "    for item in df['data'].values.tolist():\n",
    "        results = pd.concat([results, pd.DataFrame(item)])\n",
    "        \n",
    "    results = results.apply(get_public_metrics, axis=1)\n",
    "        \n",
    "    results = results.reset_index()\n",
    "    del results['index']\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack the tweets - this gives you dataframe with tweets\n",
    "tweets = get_tweets(df_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
