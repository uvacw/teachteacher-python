{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you didn't download the following language model from `SpaCy` yet, you may want to do so. Please not that this is not the best model (its geared towards efficiency rather than accuracy). The larger model can also be used (in the case of English language: `en_core_web_trf`. For instructions on installing `SpaCy`, see [here](https://spacy.io/usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Python/3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.61.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (41.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.20.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.27.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/anne/Library/Python/3.8/lib/python/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "mystopwords = stopwords.words(\"english\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "infowarsfiles = glob('articles/*/Infowars/*')\n",
    "infowarsarticles = []\n",
    "for filename in infowarsfiles:\n",
    "    with open(filename) as f:\n",
    "        infowarsarticles.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you could take random sample if you want to play around with smaller data:\n",
    "\n",
    "```python\n",
    "articles =random.sample(infowarsarticles, 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have imported number 2000 docs\n",
      "\n",
      "\n",
      "\n",
      "the first entry looks like this:\n",
      "\n",
      "\n",
      "Former Virginia Gov. Terry McAuliffe announced within minutes of Justice Kavanaughs appointment to the Supreme Court McAuliffe that he was predicting doom for millions.\n",
      "\n",
      "The nomination of Judge Brett Kavanaugh will threaten the lives of millions of Americans for decades to come and will morph our Supreme Court into a political arm of the right-wing Republican Party, McAuliffe said.\n",
      "\n",
      "Of course the policies of the left literally do kill millions. Abortions kill roughly 700,000 Americans per year. Open borders result in the DUI deaths of roughly 5000 Americans per year by drunk-driving illegal aliens, not to mention the flow of heroin over the southern border reaching epidemic proportions in the U.S., killing roughly 16,000 per year.\n",
      "\n",
      "Add that together and just the policies of Abortion and Open borders kill 721,000 American citizens per year. That is roughly 7,210,000 American Citizens killed per decade by the policies of the left.\n"
     ]
    }
   ],
   "source": [
    "print(f\"I have imported number {len(infowarsarticles)} docs\\n\\n\\n\") #check whether we have some data\n",
    "print(f\"the first entry looks like this:\\n\\n\\n{infowarsarticles[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with pre-processing in `SpaCy`\n",
    "\n",
    "It makes sense to start your pre-processing in `SpaCy` (at least, if you want to use that module), as `SpaCy`  expect raw text data that is not yet cleaned or tokenized in some way. \n",
    "\n",
    "In the following code block, we'll apply lemmatization and tokenization in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatized_articles = [[token.lemma_ for token in nlp(art)] for art in infowarsarticles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether that worked out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized: ['former', 'Virginia', 'Gov.', 'Terry', 'McAuliffe', 'announce', 'within', 'minute', 'of', 'Justice']\n",
      "\n",
      "\n",
      "original: ['Former', 'Virginia', 'Gov.', 'Terry', 'McAuliffe', 'announced', 'within', 'minutes', 'of', 'Justice']\n"
     ]
    }
   ],
   "source": [
    "print(f\"lemmatized: {lemmatized_articles[0][:10]}\\n\\n\")\n",
    "print(f\"original: {infowarsarticles[0].split()[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to do more with SpaCy, do that before moving on... \n",
    "\n",
    "For example, you could extract the 'person' entities if you like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[[token.label_ for token in nlp(art)] for art in infowarsarticles]\n",
    "\n",
    "def get_ents(x):\n",
    "    return [(ent.label_, ent) for ent in x.ents if ent.label_ == 'PERSON']\n",
    "\n",
    "entities = [get_ents(nlp(art)) for art in infowarsarticles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PERSON', Terry McAuliffe),\n",
       " ('PERSON', Kavanaughs),\n",
       " ('PERSON', Brett Kavanaugh),\n",
       " ('PERSON', Citizens)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower case and remove stopwords\n",
    "\n",
    "Next, we'll write a function to lowercase the data and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lower_and_remove_stopwords(x):\n",
    "    return [i.lower() for i in x if i not in mystopwords] \n",
    "\n",
    "clean = [lower_and_remove_stopwords(doc) for doc in lemmatized_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without stopwords and lowercased: ['former', 'virginia', 'gov.', 'terry', 'mcauliffe', 'announce', 'within', 'minute', 'justice', 'kavanaughs']\n",
      "\n",
      "\n",
      "original: ['Former', 'Virginia', 'Gov.', 'Terry', 'McAuliffe', 'announced', 'within', 'minutes', 'of', 'Justice']\n"
     ]
    }
   ],
   "source": [
    "print(f\"without stopwords and lowercased: {clean[0][:10]}\\n\\n\")\n",
    "print(f\"original: {infowarsarticles[0].split()[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bigrams and/or trigrams if you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_bigrams = [[\"_\".join(tup) for tup in nltk.ngrams(art,2)] for art in clean]\n",
    "articles_trigrams = [[\"_\".join(tup) for tup in nltk.ngrams(art,3)] for art in clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams: ['former_virginia', 'virginia_gov.', 'gov._terry', 'terry_mcauliffe', 'mcauliffe_announce', 'announce_within', 'within_minute', 'minute_justice', 'justice_kavanaughs', 'kavanaughs_appointment']\n",
      "\n",
      "\n",
      "trigrams: ['former_virginia', 'virginia_gov.', 'gov._terry', 'terry_mcauliffe', 'mcauliffe_announce', 'announce_within', 'within_minute', 'minute_justice', 'justice_kavanaughs', 'kavanaughs_appointment']\n",
      "\n",
      "\n",
      "original: ['Former', 'Virginia', 'Gov.', 'Terry', 'McAuliffe', 'announced', 'within', 'minutes', 'of', 'Justice']\n"
     ]
    }
   ],
   "source": [
    "print(f\"bigrams: {articles_bigrams[0][:10]}\\n\\n\")\n",
    "print(f\"trigrams: {articles_bigrams[0][:10]}\\n\\n\")\n",
    "print(f\"original: {infowarsarticles[0].split()[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
